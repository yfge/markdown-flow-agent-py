# MarkdownFlow Agent (Python)

**ç”¨äºå°† [MarkdownFlow](https://markdownflow.ai) æ–‡æ¡£è½¬æ¢ä¸ºä¸ªæ€§åŒ–ã€AI é©±åŠ¨äº¤äº’å¼å†…å®¹çš„ Python åç«¯è§£æå·¥å…·åŒ…ã€‚**

MarkdownFlowï¼ˆä¹Ÿç§°ä¸º MDFlow æˆ– markdown-flowï¼‰é€šè¿‡ AI æ‰©å±•äº†æ ‡å‡† Markdownï¼Œç”¨äºåˆ›å»ºä¸ªæ€§åŒ–çš„äº¤äº’å¼é¡µé¢ã€‚æˆ‘ä»¬çš„å£å·æ˜¯ï¼š**"ä¸€æ¬¡åˆ›ä½œï¼Œåƒäººåƒé¢"**ã€‚

<div align="center">

[![PyPI version](https://badge.fury.io/py/markdown-flow.svg)](https://badge.fury.io/py/markdown-flow)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Type Hints](https://img.shields.io/badge/Type_Hints-Enabled-green.svg)](https://docs.python.org/3/library/typing.html)

[English](README.md) | ç®€ä½“ä¸­æ–‡

</div>

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install markdown-flow
# æˆ–
pip install -e .  # ç”¨äºå¼€å‘
```

### åŸºç¡€ç”¨æ³•

```python
from markdown_flow import MarkdownFlow, ProcessMode

# ç®€å•çš„å†…å®¹å¤„ç†
document = """
ä½ å¥½ {{name}}ï¼è®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸‹ä½ çš„ Python æŠ€èƒ½ã€‚

?[%{{level}} åˆå­¦è€… | ä¸­çº§ | é«˜çº§]

æ ¹æ®ä½ çš„ {{level}} æ°´å¹³ï¼Œè¿™é‡Œæœ‰ä¸€äº›å»ºè®®...
"""

mf = MarkdownFlow(document)
variables = mf.extract_variables()  # è¿”å›ï¼š{'name', 'level'}
blocks = mf.get_all_blocks()        # è·å–è§£æçš„æ–‡æ¡£å—
```

### LLM é›†æˆ

```python
from markdown_flow import MarkdownFlow, ProcessMode
from your_llm_provider import YourLLMProvider

# ç”¨ LLM æä¾›ç¨‹åºåˆå§‹åŒ–
llm_provider = YourLLMProvider(api_key="your-key")
mf = MarkdownFlow(document, llm_provider=llm_provider)

# ä½¿ç”¨ä¸åŒæ¨¡å¼å¤„ç†
result = await mf.process(
    block_index=0,
    mode=ProcessMode.COMPLETE,
    variables={'name': 'Alice', 'level': 'ä¸­çº§'}
)
```

### æµå¼å“åº”

```python
# å®æ—¶å“åº”çš„æµå¤„ç†
async for chunk in mf.process(
    block_index=0,
    mode=ProcessMode.STREAM,
    variables={'name': 'Bob'}
):
    print(chunk.content, end='')
```

### äº¤äº’å¼å…ƒç´ 

```python
# å¤„ç†ç”¨æˆ·äº¤äº’
document = """
ä½ åçˆ±çš„ç¼–ç¨‹è¯­è¨€æ˜¯ä»€ä¹ˆï¼Ÿ

?[%{{language}} Python | JavaScript | Go | å…¶ä»–...]

?[ç»§ç»­ | è·³è¿‡]
"""

mf = MarkdownFlow(document)
blocks = mf.get_all_blocks()

for block in blocks:
    if block.block_type == BlockType.INTERACTION:
        # å¤„ç†ç”¨æˆ·äº¤äº’
        print(f"äº¤äº’ï¼š{block.content}")
```

## ğŸ“– API å‚è€ƒ

### æ ¸å¿ƒç±»

#### MarkdownFlow

ç”¨äºè§£æå’Œå¤„ç† MarkdownFlow æ–‡æ¡£çš„ä¸»è¦ç±»ã€‚

```python
class MarkdownFlow:
    def __init__(
        self,
        content: str,
        llm_provider: Optional[LLMProvider] = None
    ) -> None: ...

    def get_all_blocks(self) -> List[Block]: ...
    def extract_variables(self) -> Set[str]: ...

    async def process(
        self,
        block_index: int,
        mode: ProcessMode = ProcessMode.COMPLETE,
        variables: Optional[Dict[str, str]] = None,
        user_input: Optional[str] = None
    ) -> LLMResult: ...
```

**æ–¹æ³•ï¼š**

- `get_all_blocks()` - å°†æ–‡æ¡£è§£æä¸ºç»“æ„åŒ–å—
- `extract_variables()` - æå–æ‰€æœ‰ `{{variable}}` å’Œ `%{{variable}}` æ¨¡å¼
- `process()` - ä½¿ç”¨ç»Ÿä¸€æ¥å£é€šè¿‡ LLM å¤„ç†å—

**ç¤ºä¾‹ï¼š**

```python
mf = MarkdownFlow("""
# æ¬¢è¿ {{name}}ï¼

é€‰æ‹©ä½ çš„ç»éªŒï¼š?[%{{exp}} åˆå­¦è€… | ä¸“å®¶]

ä½ çš„ç»éªŒæ°´å¹³æ˜¯ {{exp}}ã€‚
""")

print("å˜é‡ï¼š", mf.extract_variables())  # {'name', 'exp'}
print("å—æ•°ï¼š", len(mf.get_all_blocks()))   # 3
```

#### ProcessMode

ä¸åŒç”¨ä¾‹çš„å¤„ç†æ¨¡å¼æšä¸¾ã€‚

```python
class ProcessMode(Enum):
    PROMPT_ONLY = "prompt_only"  # ä»…ç”Ÿæˆæç¤ºï¼Œä¸è°ƒç”¨ LLM
    COMPLETE = "complete"        # éæµå¼ LLM å¤„ç†
    STREAM = "stream"           # æµå¼ LLM å“åº”
```

**ç”¨æ³•ï¼š**

```python
# ä»…ç”Ÿæˆæç¤º
prompt_result = await mf.process(0, ProcessMode.PROMPT_ONLY)
print(prompt_result.content)  # åŸå§‹æç¤ºæ–‡æœ¬

# å®Œæ•´å“åº”
complete_result = await mf.process(0, ProcessMode.COMPLETE)
print(complete_result.content)  # å®Œæ•´çš„ LLM å“åº”

# æµå¼å“åº”
async for chunk in mf.process(0, ProcessMode.STREAM):
    print(chunk.content, end='')
```

#### LLMProvider

ç”¨äºå®ç° LLM æä¾›ç¨‹åºçš„æŠ½è±¡åŸºç±»ã€‚

```python
from abc import ABC, abstractmethod
from typing import AsyncGenerator

class LLMProvider(ABC):
    @abstractmethod
    async def complete(self, prompt: str) -> LLMResult: ...

    @abstractmethod
    async def stream(self, prompt: str) -> AsyncGenerator[str, None]: ...
```

**è‡ªå®šä¹‰å®ç°ï¼š**

```python
class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str):
        self.client = openai.AsyncOpenAI(api_key=api_key)

    async def complete(self, prompt: str) -> LLMResult:
        response = await self.client.completions.create(
            model="gpt-3.5-turbo",
            prompt=prompt,
            max_tokens=500
        )
        return LLMResult(content=response.choices[0].text.strip())

    async def stream(self, prompt: str):
        stream = await self.client.completions.create(
            model="gpt-3.5-turbo",
            prompt=prompt,
            stream=True
        )
        async for chunk in stream:
            if chunk.choices[0].text:
                yield chunk.choices[0].text
```

### å—ç±»å‹

#### BlockType

MarkdownFlow æ–‡æ¡£ä¸­ä¸åŒå—ç±»å‹çš„æšä¸¾ã€‚

```python
class BlockType(Enum):
    CONTENT = "content"                    # å¸¸è§„ markdown å†…å®¹
    INTERACTION = "interaction"            # ç”¨æˆ·äº¤äº’å— (?[...])
    PRESERVED_CONTENT = "preserved_content" # ç”¨ === æ ‡è®°åŒ…è£…çš„å†…å®¹
```

**å—ç»“æ„ï¼š**

```python
# å†…å®¹å— - ç”± LLM å¤„ç†
"""
ä½ å¥½ {{name}}ï¼æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„å¹³å°ã€‚
"""

# äº¤äº’å— - éœ€è¦ç”¨æˆ·è¾“å…¥
"""
?[%{{choice}} é€‰é¡¹ A | é€‰é¡¹ B | è¾“å…¥è‡ªå®šä¹‰é€‰é¡¹...]
"""

# ä¿ç•™å†…å®¹ - åŸæ ·è¾“å‡º
"""
===
æ­¤å†…å®¹å®Œå…¨æŒ‰åŸæ ·ä¿ç•™ã€‚
æ²¡æœ‰ LLM å¤„ç†æˆ–å˜é‡æ›¿æ¢ã€‚
===
"""
```

### äº¤äº’ç±»å‹

#### InteractionType

è§£æåçš„äº¤äº’æ ¼å¼ç±»å‹ã€‚

```python
class InteractionType(NamedTuple):
    name: str                    # ç±»å‹åç§°
    variable: Optional[str]      # è¦åˆ†é…çš„å˜é‡ (%{{var}})
    buttons: List[str]          # æŒ‰é’®é€‰é¡¹
    question: Optional[str]      # æ–‡æœ¬è¾“å…¥é—®é¢˜
    has_text_input: bool        # æ˜¯å¦å…è®¸æ–‡æœ¬è¾“å…¥
```

**æ”¯æŒçš„æ ¼å¼ï¼š**

```python
# TEXT_ONLYï¼šå¸¦é—®é¢˜çš„æ–‡æœ¬è¾“å…¥
"?[%{{name}} ä½ çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ]"

# BUTTONS_ONLYï¼šä»…æŒ‰é’®é€‰æ‹©
"?[%{{level}} åˆå­¦è€… | ä¸­çº§ | é«˜çº§]"

# BUTTONS_WITH_TEXTï¼šæŒ‰é’®ä¸å¤‡ç”¨æ–‡æœ¬è¾“å…¥
"?[%{{preference}} é€‰é¡¹ A | é€‰é¡¹ B | è¯·æŒ‡å®š...]"

# NON_ASSIGNMENT_BUTTONï¼šæ˜¾ç¤ºæŒ‰é’®ä½†ä¸åˆ†é…å˜é‡
"?[ç»§ç»­ | å–æ¶ˆ | è¿”å›]"
```

### å®ç”¨å‡½æ•°

#### å˜é‡æ“ä½œ

```python
def extract_variables_from_text(text: str) -> Set[str]:
    """æå–æ‰€æœ‰ {{variable}} å’Œ %{{variable}} æ¨¡å¼ã€‚"""

def replace_variables_in_text(text: str, variables: dict) -> str:
    """æ›¿æ¢ {{variable}} æ¨¡å¼çš„å€¼ï¼Œä¿ç•™ %{{variable}}ã€‚"""

# ç¤ºä¾‹
text = "ä½ å¥½ {{name}}ï¼é€‰æ‹©ï¼š?[%{{level}} åŸºç¡€ | é«˜çº§]"
vars = extract_variables_from_text(text)  # {'name', 'level'}
result = replace_variables_in_text(text, {'name': 'Alice'})
# è¿”å›ï¼š"ä½ å¥½ Aliceï¼é€‰æ‹©ï¼š?[%{{level}} åŸºç¡€ | é«˜çº§]"
```

#### äº¤äº’å¤„ç†

```python
def InteractionParser.parse(content: str) -> InteractionType:
    """å°†äº¤äº’å—è§£æä¸ºç»“æ„åŒ–æ ¼å¼ã€‚"""

def extract_interaction_question(content: str) -> str:
    """ä»äº¤äº’å—ä¸­æå–é—®é¢˜æ–‡æœ¬ã€‚"""

def generate_smart_validation_template(interaction_type: InteractionType) -> str:
    """ä¸ºäº¤äº’ç”ŸæˆéªŒè¯æ¨¡æ¿ã€‚"""

# ç¤ºä¾‹
parser_result = InteractionParser.parse("%{{choice}} A | B | è¾“å…¥è‡ªå®šä¹‰...")
print(parser_result.name)          # "BUTTONS_WITH_TEXT"
print(parser_result.variable)      # "choice"
print(parser_result.buttons)       # ["A", "B"]
print(parser_result.question)      # "è¾“å…¥è‡ªå®šä¹‰..."
```

### ç±»å‹å’Œæ¨¡å‹

```python
# æ ¸å¿ƒæ•°æ®ç»“æ„
from dataclasses import dataclass
from typing import Optional, List, Dict, Set

@dataclass
class Block:
    content: str
    block_type: BlockType
    index: int

@dataclass  
class LLMResult:
    content: str
    metadata: Optional[Dict] = None

# å˜é‡ç³»ç»Ÿç±»å‹
Variables = Dict[str, str]  # å˜é‡å -> å€¼æ˜ å°„

# æ‰€æœ‰ç±»å‹éƒ½å·²å¯¼å‡ºä¾›ä½¿ç”¨
from markdown_flow import (
    Block, LLMResult, Variables,
    BlockType, InteractionType, ProcessMode
)
```

## ğŸ§© é«˜çº§ç¤ºä¾‹

### è‡ªå®šä¹‰ LLM æä¾›ç¨‹åºé›†æˆ

```python
from markdown_flow import MarkdownFlow, LLMProvider, LLMResult
import httpx

class CustomAPIProvider(LLMProvider):
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.client = httpx.AsyncClient()

    async def complete(self, prompt: str) -> LLMResult:
        response = await self.client.post(
            f"{self.base_url}/complete",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={"prompt": prompt, "max_tokens": 1000}
        )
        data = response.json()
        return LLMResult(content=data["text"])

    async def stream(self, prompt: str):
        async with self.client.stream(
            "POST",
            f"{self.base_url}/stream",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={"prompt": prompt}
        ) as response:
            async for chunk in response.aiter_text():
                if chunk.strip():
                    yield chunk

# ç”¨æ³•
provider = CustomAPIProvider("https://api.example.com", "your-key")
mf = MarkdownFlow(document, llm_provider=provider)
```

### å¤šå—æ–‡æ¡£å¤„ç†

```python
async def process_conversation():
    conversation = """
# AI åŠ©æ‰‹

ä½ å¥½ {{user_name}}ï¼æˆ‘åœ¨è¿™é‡Œå¸®åŠ©ä½ å­¦ä¹  Pythonã€‚

---

ä½ å½“å‰çš„ç»éªŒæ°´å¹³å¦‚ä½•ï¼Ÿ

?[%{{experience}} å®Œå…¨åˆå­¦è€… | æœ‰ä¸€äº›ç»éªŒ | æœ‰ç»éªŒ]

---

æ ¹æ®ä½ çš„ {{experience}} æ°´å¹³ï¼Œè®©æˆ‘åˆ›å»ºä¸€ä¸ªä¸ªæ€§åŒ–çš„å­¦ä¹ è®¡åˆ’ã€‚

è¯¥è®¡åˆ’å°†åŒ…æ‹¬ç¬¦åˆä½ èƒŒæ™¯çš„ {{topics}}ã€‚

---

ä½ æƒ³ä»åŸºç¡€å¼€å§‹å—ï¼Ÿ

?[å¼€å§‹å­¦ä¹  | è‡ªå®šä¹‰è®¡åˆ’ | æé—®]
"""

    mf = MarkdownFlow(conversation, llm_provider=your_provider)
    blocks = mf.get_all_blocks()

    variables = {
        'user_name': 'Alice',
        'experience': 'æœ‰ä¸€äº›ç»éªŒ',
        'topics': 'ä¸­çº§æ¦‚å¿µå’Œå®é™…é¡¹ç›®'
    }

    for i, block in enumerate(blocks):
        if block.block_type == BlockType.CONTENT:
            print(f"\n--- å¤„ç†å— {i} ---")
            result = await mf.process(
                block_index=i,
                mode=ProcessMode.COMPLETE,
                variables=variables
            )
            print(result.content)
        elif block.block_type == BlockType.INTERACTION:
            print(f"\n--- ç”¨æˆ·äº¤äº’å— {i} ---")
            print(block.content)
```

### å¸¦è¿›åº¦è·Ÿè¸ªçš„æµå¼å¤„ç†

```python
from markdown_flow import MarkdownFlow, ProcessMode
import asyncio

async def stream_with_progress():
    document = """
ä¸º {{user_name}} ç”Ÿæˆä¸€ä¸ªå…¨é¢çš„ Python æ•™ç¨‹ï¼Œ
ä¸“æ³¨äº {{topic}}ï¼ŒåŒ…å«å®é™…ç¤ºä¾‹ã€‚

åŒ…æ‹¬ä»£ç æ ·ä¾‹ã€è§£é‡Šå’Œç»ƒä¹ ã€‚
"""

    mf = MarkdownFlow(document, llm_provider=your_provider)

    print("å¼€å§‹æµå¤„ç†...")
    content = ""
    chunk_count = 0

    async for chunk in mf.process(
        block_index=0,
        mode=ProcessMode.STREAM,
        variables={
            'user_name': 'å¼€å‘è€…',
            'topic': 'å¼‚æ­¥ç¼–ç¨‹'
        }
    ):
        content += chunk.content
        chunk_count += 1

        # æ˜¾ç¤ºè¿›åº¦
        if chunk_count % 10 == 0:
            print(f"å·²æ¥æ”¶ {chunk_count} ä¸ªå—ï¼Œ{len(content)} ä¸ªå­—ç¬¦")

        # å®æ—¶å¤„ç†
        if chunk.content.endswith('\n'):
            # å¤„ç†å®Œæ•´è¡Œ
            lines = content.strip().split('\n')
            if lines:
                latest_line = lines[-1]
                # å¯¹å®Œæ•´è¡Œåšä¸€äº›æ“ä½œ
                pass

    print(f"\næµå¤„ç†å®Œæˆï¼æ€»è®¡ï¼š{chunk_count} ä¸ªå—ï¼Œ{len(content)} ä¸ªå­—ç¬¦")
    return content
```

### äº¤äº’å¼æ–‡æ¡£ç”Ÿæˆå™¨

```python
from markdown_flow import MarkdownFlow, BlockType, InteractionType

class InteractiveDocumentBuilder:
    def __init__(self, template: str, llm_provider):
        self.mf = MarkdownFlow(template, llm_provider)
        self.user_responses = {}
        self.current_block = 0

    async def start_interaction(self):
        blocks = self.mf.get_all_blocks()

        for i, block in enumerate(blocks):
            if block.block_type == BlockType.CONTENT:
                # ä½¿ç”¨å½“å‰å˜é‡å¤„ç†å†…å®¹å—
                result = await self.mf.process(
                    block_index=i,
                    mode=ProcessMode.COMPLETE,
                    variables=self.user_responses
                )
                print(f"\nå†…å®¹ï¼š{result.content}")

            elif block.block_type == BlockType.INTERACTION:
                # å¤„ç†ç”¨æˆ·äº¤äº’
                response = await self.handle_interaction(block.content)
                if response:
                    self.user_responses.update(response)

    async def handle_interaction(self, interaction_content: str):
        from markdown_flow.utils import InteractionParser

        interaction = InteractionParser.parse(interaction_content)
        print(f"\n{interaction_content}")

        if interaction.name == "BUTTONS_ONLY":
            print("é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š")
            for i, button in enumerate(interaction.buttons, 1):
                print(f"{i}. {button}")

            choice = input("è¾“å…¥é€‰æ‹©ç¼–å·ï¼š")
            try:
                selected = interaction.buttons[int(choice) - 1]
                return {interaction.variable: selected}
            except (ValueError, IndexError):
                print("æ— æ•ˆé€‰æ‹©")
                return await self.handle_interaction(interaction_content)

        elif interaction.name == "TEXT_ONLY":
            response = input(f"{interaction.question}ï¼š")
            return {interaction.variable: response}

        return {}

# ç”¨æ³•
template = """
æ¬¢è¿ï¼è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸ªæ€§åŒ–çš„å­¦ä¹ è®¡åˆ’ã€‚

ä½ çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ
?[%{{name}} è¾“å…¥ä½ çš„åå­—]

ä½ å¥½ {{name}}ï¼ä½ æƒ³å­¦ä»€ä¹ˆï¼Ÿ
?[%{{subject}} Python | JavaScript | æ•°æ®ç§‘å­¦ | æœºå™¨å­¦ä¹ ]

å¾ˆå¥½çš„é€‰æ‹©ï¼Œ{{name}}ï¼{{subject}} æ˜¯ä¸€ä¸ªç»ä½³çš„å­¦ä¹ é¢†åŸŸã€‚
"""

builder = InteractiveDocumentBuilder(template, your_llm_provider)
await builder.start_interaction()
```

### å˜é‡ç³»ç»Ÿæ·±å…¥äº†è§£

```python
from markdown_flow import extract_variables_from_text, replace_variables_in_text

def demonstrate_variable_system():
    # åŒ…å«ä¸¤ç§å˜é‡ç±»å‹çš„å¤æ‚æ–‡æ¡£
    document = """
    æ¬¢è¿ {{user_name}} æ¥åˆ° {{course_title}} è¯¾ç¨‹ï¼

    è¯·ä¸ºä½ çš„ä½“éªŒè¯„åˆ†ï¼š?[%{{rating}} 1 | 2 | 3 | 4 | 5]

    å½“å‰è¿›åº¦ï¼š{{progress_percent}}%
    ä½œä¸šæˆªæ­¢ï¼š{{due_date}}

    ä½ çš„ %{{rating}} è¯„åˆ†å¸®åŠ©æˆ‘ä»¬æ”¹è¿›è¯¾ç¨‹å†…å®¹ã€‚
    """

    # æå–æ‰€æœ‰å˜é‡
    all_vars = extract_variables_from_text(document)
    print(f"æ‰¾åˆ°çš„æ‰€æœ‰å˜é‡ï¼š{all_vars}")
    # è¾“å‡ºï¼š{'user_name', 'course_title', 'rating', 'progress_percent', 'due_date'}

    # ä»…æ›¿æ¢ {{variable}} æ¨¡å¼ï¼Œä¿ç•™ %{{variable}}
    replacements = {
        'user_name': 'Alice',
        'course_title': 'Python é«˜çº§',
        'progress_percent': '75',
        'due_date': '2024-12-15',
        'rating': '4'  # ç”±äº %{{}} æ ¼å¼ï¼Œè¿™ä¸ªä¸ä¼šè¢«æ›¿æ¢
    }

    result = replace_variables_in_text(document, replacements)
    print("\næ›¿æ¢åï¼š")
    print(result)

    # %{{rating}} ä¿æŒä¸å˜ä¾› LLM å¤„ç†ï¼Œ
    # è€Œ {{user_name}}ã€{{course_title}} ç­‰è¢«æ›¿æ¢

demonstrate_variable_system()
```

## ğŸŒ MarkdownFlow ç”Ÿæ€ç³»ç»Ÿ

markdown-flow-agent-py æ˜¯ MarkdownFlow ç”Ÿæ€ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºåˆ›å»ºä¸ªæ€§åŒ–ã€AI é©±åŠ¨çš„äº¤äº’å¼æ–‡æ¡£ï¼š

- **[markdown-flow](https://github.com/ai-shifu/markdown-flow)** - åŒ…å«ä¸»é¡µã€æ–‡æ¡£å’Œäº¤äº’å¼ playground çš„ä¸»ä»“åº“
- **[markdown-flow-ui](https://github.com/ai-shifu/markdown-flow-ui)** - ç”¨äºæ¸²æŸ“äº¤äº’å¼ MarkdownFlow æ–‡æ¡£çš„ React ç»„ä»¶åº“
- **[markdown-it-flow](https://github.com/ai-shifu/markdown-it-flow)** - ç”¨äºè§£æå’Œæ¸²æŸ“ MarkdownFlow è¯­æ³•çš„ markdown-it æ’ä»¶
- **[remark-flow](https://github.com/ai-shifu/remark-flow)** - ç”¨äºåœ¨ React åº”ç”¨ä¸­è§£æå’Œå¤„ç† MarkdownFlow è¯­æ³•çš„ Remark æ’ä»¶

## ğŸ’– èµåŠ©å•†

<div align="center">
  <a href="https://ai-shifu.cn">
    <img src="https://raw.githubusercontent.com/ai-shifu/ai-shifu/main/assets/logo_zh.png" alt="AI å¸ˆå‚…" width="150" />
  </a>
  <p><strong><a href="https://ai-shifu.cn">AI-Shifu.cn</a></strong></p>
  <p>AI é©±åŠ¨çš„ä¸ªæ€§åŒ–å­¦ä¹ å¹³å°</p>
</div>

## ğŸ“„ è®¸å¯è¯

MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [Python](https://www.python.org/) æä¾›å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€
- [Ruff](https://docs.astral.sh/ruff/) æä¾›é—ªç”µèˆ¬å¿«é€Ÿçš„ Python ä»£ç æ£€æŸ¥å’Œæ ¼å¼åŒ–
- [MyPy](https://mypy.readthedocs.io/) æä¾›é™æ€ç±»å‹æ£€æŸ¥
- [Commitizen](https://commitizen-tools.github.io/commitizen/) æä¾›æ ‡å‡†åŒ–æäº¤æ¶ˆæ¯
- [Pre-commit](https://pre-commit.com/) æä¾›è‡ªåŠ¨åŒ–ä»£ç è´¨é‡æ£€æŸ¥

## ğŸ“ æ”¯æŒ

- ğŸ“– [æ–‡æ¡£](https://github.com/ai-shifu/markdown-flow-agent-py#readme)
- ğŸ› [é—®é¢˜è·Ÿè¸ª](https://github.com/ai-shifu/markdown-flow-agent-py/issues)
- ğŸ’¬ [è®¨è®º](https://github.com/ai-shifu/markdown-flow-agent-py/discussions)
